# IntegrateALL_v2 Pipeline ğŸ§¬

## ğŸš€ **Smart Installation mit Auto-Konfiguration**

### âš¡ **Ein-Befehl Setup**

```bash
# Repository klonen
git clone https://github.com/NadineWolgast/IntegrateALL_v2.git
cd IntegrateALL_v2

# Pipeline installieren (vollautomatisch mit Pfad-Erkennung!)
./install_simple.sh

# Pipeline aktivieren
source activate_pipeline.sh
```

**Das war's!** Die Pipeline ist vollstÃ¤ndig installiert und konfiguriert! ğŸ‰

## âœ¨ **Automatische Konfiguration**

Die Installation erkennt automatisch:
- ğŸ” **Pipeline-Verzeichnis** (aktueller Pfad)
- ğŸ **Conda-Installation** (Miniconda/Anaconda)  
- ğŸ  **Benutzer-Home-Verzeichnis**
- ğŸ“ **SLURM Submit-Scripts** werden generiert
- âš™ï¸ **Cluster-Konfiguration** wird erstellt

### ğŸ“ **Automatisch erstellte Dateien:**
- `submit_pipeline.sh` - SLURM Batch-Script mit korrekten Pfaden
- `config/cluster.yaml` - Optimierte Ressourcen-Konfiguration  
- `activate_pipeline.sh` - Environment-Aktivierung
- `config/samples_template.tsv` - Sample-Konfiguration Template

## ğŸ”§ **Manuelle Pfad-Anpassung (optional)**

Falls du spezielle Pfade brauchst:

```bash
# Interaktive Konfiguration
./setup_paths.sh

# Direkte Pfad-Angabe
./setup_paths.sh /work_beegfs/user/pipeline /opt/conda

# Nur Basis-Pfad setzen
./setup_paths.sh /custom/pipeline/path
```

## ğŸ“Š **Sample-Konfiguration**

```bash
# Template kopieren und bearbeiten
cp config/samples_template.tsv config/samples.tsv
nano config/samples.tsv
```

**Format:**
```tsv
sample_id	fastq1	fastq2	condition	batch
sample1	/path/to/sample1_R1.fastq.gz	/path/to/sample1_R2.fastq.gz	B-ALL	batch1
sample2	/path/to/sample2_R1.fastq.gz	/path/to/sample2_R2.fastq.gz	B-ALL	batch1
```

## ğŸš€ **Pipeline ausfÃ¼hren**

### **SLURM-Cluster:**
```bash
# Job einreichen
sbatch submit_pipeline.sh

# Status prÃ¼fen
squeue -u $(whoami)

# Logs verfolgen  
tail -f integrateall_*.out
```

### **Lokal:**
```bash
# Environment aktivieren
source activate_pipeline.sh

# Pipeline starten
snakemake --cores 16 --use-conda

# Dry-run (Test)
snakemake --dry-run --printshellcmds
```

## ğŸŒ **Multi-Environment Support**

Die Pipeline funktioniert automatisch auf:

### **Workstations/Laptops:**
- âœ… Lokale Conda-Installation
- âœ… Automatische Pfad-Erkennung
- âœ… Resource-Anpassung

### **SLURM-Cluster:**  
- âœ… Auto-generierte Batch-Scripts
- âœ… Cluster-Ressourcen-Konfiguration
- âœ… Job-Dependency-Management

### **Cloud-Systeme:**
- âœ… Pfad-agnostische Installation  
- âœ… Container-ready
- âœ… Skalierbare Konfiguration

## ğŸ“‹ **Pipeline-Komponenten (27 Jobs)**

### **Quality Control & Alignment**
- FastQC, MultiQC fÃ¼r Input-QC
- STAR alignment mit 2-pass mapping
- BAM indexing und QC-Statistiken

### **Variant Calling (GATK Pipeline)**
- AddOrReplaceReadGroups (fÃ¼r STAR-Output)
- MarkDuplicates  
- SplitNCigarReads (RNA-spezifisch)
- HaplotypeCaller
- VariantFiltration

### **Fusion Detection**
- Arriba via offiziellen Snakemake Wrapper
- Automatische Datenbank-Downloads
- Fusion-Integration und Annotation

### **B-ALL Classification**
- ALLCatchR (Genexpressions-basierte Klassifikation)
- B-ALL Subtyp-Vorhersage  
- Konfidenz-Scores

### **CNV Analysis**
- RNAseqCNV (Copy Number Variation Detection)
- Chromosomale InstabilitÃ¤t
- Ploidie-SchÃ¤tzung

### **Reporting & Summary**
- Sample-spezifische Reports
- Pipeline-Summary
- Interactive HTML Reports

## ğŸ¯ **FÃ¼r jeden User geeignet!**

**AnfÃ¤nger:** Ein-Befehl Installation, alles automatisch  
**Fortgeschrittene:** Flexible Pfad-Konfiguration  
**Cluster-Admins:** Vorkonfigurierte SLURM-Integration  
**Entwickler:** Modulare, erweiterbare Architektur

Die IntegrateALL_v2 Pipeline ist **universell deployment-ready**! ğŸŒŸ